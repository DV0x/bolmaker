TITLE: Mistral AI OCR API Request Payload Example
DESCRIPTION: Example JSON payload for making a request to the Mistral AI OCR API, demonstrating how to specify document details, pages, and structured annotation formats for both bounding box and document-level output.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: JSON
CODE:
```
{
  "model": "string",
  "id": "string",
  "document": {
    "document_url": "string",
    "document_name": "string",
    "type": "document_url"
  },
  "pages": [
    0
  ],
  "include_image_base64": true,
  "image_limit": 0,
  "image_min_size": 0,
  "bbox_annotation_format": {
    "type": "text",
    "json_schema": {
      "name": "string",
      "description": "string",
      "schema": {},
      "strict": false
    }
  },
  "document_annotation_format": {
    "type": "text",
    "json_schema": {
      "name": "string",
      "description": "string",
      "schema": {},
      "strict": false
    }
  }
}
```

----------------------------------------

TITLE: Generic Mistral AI API Request Payload Example
DESCRIPTION: Example JSON payload for a generic Mistral AI API request, detailing input parameters, streaming options, and comprehensive completion arguments.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: json
CODE:
```
{
  "inputs": "string",
  "stream": true,
  "store": true,
  "handoff_execution": "client",
  "completion_args": {
    "stop": "string",
    "presence_penalty": -2,
    "frequency_penalty": -2,
    "temperature": 0.3,
    "top_p": 1,
    "max_tokens": 0,
    "random_seed": 0,
    "prediction": {
      "type": "content",
      "content": ""
    },
    "response_format": {
      "type": "text",
      "json_schema": {
        "name": "string",
        "description": "string",
        "schema": { },
        "strict": false
      }
    },
    "tool_choice": "auto"
  }
}
```

----------------------------------------

TITLE: Start Conversation with Mistral AI API
DESCRIPTION: Provides examples in Python, TypeScript, and cURL for initiating a conversation with the Mistral AI API. Demonstrates how to start conversations using an `agent_id` or by directly specifying a `model`, and how to provide inputs as a simple string or a structured message array.
SOURCE: https://docs.mistral.ai/agents/agents_basics

LANGUAGE: python
CODE:
```
response = client.beta.conversations.start(
    agent_id=simple_agent.id,
    inputs="Who is Albert Einstein?",
    #store=False
)
```

LANGUAGE: python
CODE:
```
response = client.beta.conversations.start(
    agent_id=simple_agent.id,
    inputs=[{"role": "user", "content": "Who is Albert Einstein?"}],
    #store=False
)
```

LANGUAGE: python
CODE:
```
response = client.beta.conversations.start(
    model="mistral-medium-latest",
    inputs=[{"role": "user", "content": "Who is Albert Einstein?"}],
    #store=False
)
```

LANGUAGE: typescript
CODE:
```
let conversation = await client.beta.conversations.start({
      agentId: websearchAgent.id,
      inputs:"Who is Albert Einstein?",
      //store:false
});
```

LANGUAGE: typescript
CODE:
```
let conversationMultipleEntries = await client.beta.conversations.start({
    agentId: websearchAgent.id,
    inputs:[{role: "user", content:"Who is Albert Einstein?"}],
    //store:false
});
```

LANGUAGE: typescript
CODE:
```
let conversationMultipleEntries = await client.beta.conversations.start({
    model: "mistral-medium-latest",
    inputs:[{role: "user", content:"Who is Albert Einstein?"}],
    //store:false
});
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/conversations" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
     "inputs": "Who is Albert Einstein?",
     "stream": false,
     "agent_id": "<agent_id>"
  }'
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/conversations" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
     "inputs": [
       {
         "role": "user",
         "content": "Who is Albert Einstein?",
         "object": "entry",
         "type": "message.input"
       }
     ],
     "stream": false,
     "agent_id": "<agent_id>"
  }'
```

----------------------------------------

TITLE: Mistral AI Chat Moderations API Reference
DESCRIPTION: Documentation for the Mistral AI Chat Moderations API, outlining request parameters for moderating chat content and example request/response payloads.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Method: POST
Endpoint: /v1/chat/moderations
Base URL: https://api.mistral.ai/v1/chat/moderations
Authorization: ApiKey

Request Body Schema (application/json):
- input (array of any, required): Chat to classify.
- model (string, required): ID of the model to use.

Request Sample (application/json):
{
  "input": [
    {
      "content": "string",
      "role": "system"
    }
  ],
  "model": "string"
}

Responses:
- 200: Successful Response
- 422: Validation Error

Response Sample (200, application/json):
{
  "id": "mod-e5cc70bb28c444948073e77776eb30ef",
  "model": "string",
  "results": [
    {
      "categories": {
        "property1": true,
        "property2": true
      },
      "category_scores": {
        "property1": 0,
        "property2": 0
      }
    }
  ]
}
```

----------------------------------------

TITLE: Mistral AI Embeddings API Reference
DESCRIPTION: Documentation for the Mistral AI Embeddings API, including request parameters for generating text embeddings and example request/response payloads.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Method: POST
Endpoint: /v1/embeddings
Base URL: https://api.mistral.ai/v1/embeddings
Authorization: ApiKey

Request Body Schema (application/json):
- model (string, required): ID of the model to use.
- input (string or array of strings, required): Text to embed.
- output_dimension (integer or null): The dimension of the output embeddings.
- output_dtype (string, default: "float"): Enum: "float", "int8", "uint8", "binary", "ubinary". The data type of the output embeddings.

Request Sample (application/json):
{
  "model": "mistral-embed",
  "input": [
    "Embed this sentence.",
    "As well as this one."
  ],
  "output_dimension": 0,
  "output_dtype": "float"
}

Responses:
- 200: Successful Response
- 422: Validation Error

Response Sample (200, application/json):
{
  "id": "cmpl-e5cc70bb28c444948073e77776eb30ef",
  "object": "chat.completion",
  "model": "mistral-small-latest",
  "usage": {
    "prompt_tokens": 16,
    "completion_tokens": 34,
    "total_tokens": 50
  },
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.1,
        0.2,
        0.3
      ],
      "index": 0
    }
  ]
}
```

----------------------------------------

TITLE: Create and Start a Fine-tuning Job with Mistral AI
DESCRIPTION: This snippet illustrates how to create and initiate a fine-tuning job using the Mistral AI API. It specifies the model, training/validation files (by ID), and hyperparameters like training steps and learning rate. Examples are provided for Python, TypeScript, and cURL.
SOURCE: https://docs.mistral.ai/guides/finetuning

LANGUAGE: python
CODE:
```
# create a fine-tuning job
created_jobs = client.fine_tuning.jobs.create(
    model="open-mistral-7b",
    training_files=[{"file_id": ultrachat_chunk_train.id, "weight": 1}],
    validation_files=[ultrachat_chunk_eval.id],
    hyperparameters={
        "training_steps": 10,
        "learning_rate":0.0001
    },
    auto_start=False
)

# start a fine-tuning job
client.fine_tuning.jobs.start(job_id = created_jobs.id)

created_jobs
```

LANGUAGE: typescript
CODE:
```
const createdJob = await client.jobs.create({
  model: 'open-mistral-7b',
  trainingFiles: [ultrachat_chunk_train.id],
  validationFiles: [ultrachat_chunk_eval.id],
  hyperparameters: {
    trainingSteps: 10,
    learningRate: 0.0001,
  },
});
```

LANGUAGE: curl
CODE:
```
curl https://api.mistral.ai/v1/fine_tuning/jobs \
--header "Authorization: Bearer $MISTRAL_API_KEY" \
--header 'Content-Type: application/json' \
--header 'Accept: application/json' \
--data '{
  "model": "open-mistral-7b",
  "training_files": [
    "<uuid>"
  ],
  "validation_files": [
    "<uuid>"
  ],
  "hyperparameters": {
    "training_steps": 10,
    "learning_rate": 0.0001
  }
}'
```

----------------------------------------

TITLE: Mistral AI Moderations API Reference
DESCRIPTION: Documentation for the Mistral AI Moderations API, detailing the request parameters for content moderation and example request/response payloads.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Method: POST
Endpoint: /v1/moderations
Base URL: https://api.mistral.ai/v1/moderations
Authorization: ApiKey

Request Body Schema (application/json):
- model (string, required): ID of the model to use.
- input (string or array of strings, required): Text to classify.

Request Sample (application/json):
{
  "model": "string",
  "input": "string"
}

Responses:
- 200: Successful Response
- 422: Validation Error

Response Sample (200, application/json):
{
  "id": "mod-e5cc70bb28c444948073e77776eb30ef",
  "model": "string",
  "results": [
    {
      "categories": {
        "property1": true,
        "property2": true
      },
      "category_scores": {
        "property1": 0,
        "property2": 0
      }
    }
  ]
}
```

----------------------------------------

TITLE: Start Fine-tuning Job API Endpoint
DESCRIPTION: Documents the API endpoint for initiating a fine-tuning job, including authorization, path parameters, and expected responses.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
POST /v1/fine_tuning/jobs/{job_id}/start
  - Description: Request the start of a validated fine tuning job.
  - Authorizations: ApiKey
  - Path Parameters:
    - job_id (required): string <uuid> (Job Id)
  - Responses:
    - 200 OK
  - Production Server: https://api.mistral.ai/v1/fine_tuning/jobs/{job_id}/start
```

----------------------------------------

TITLE: Perform Chat Completions with Mistral AI API
DESCRIPTION: This snippet demonstrates how to use the Mistral AI API to perform chat completions. It shows how to initialize the client with an API key and send a user message to the 'mistral-large-latest' model, then print the model's response. Requires an activated API key and the Mistral AI client library.
SOURCE: https://docs.mistral.ai/getting-started/quickstart

LANGUAGE: python
CODE:
```
import os
from mistralai import Mistral

api_key = os.environ["MISTRAL_API_KEY"]
model = "mistral-large-latest"

client = Mistral(api_key=api_key)

chat_response = client.chat.complete(
    model= model,
    messages = [
        {
            "role": "user",
            "content": "What is the best French cheese?",
        },
    ]
)
print(chat_response.choices[0].message.content)
```

LANGUAGE: typescript
CODE:
```
import { Mistral } from '@mistralai/mistralai';

const apiKey = process.env.MISTRAL_API_KEY;

const client = new Mistral({apiKey: apiKey});

const chatResponse = await client.chat.complete({
  model: 'mistral-large-latest',
  messages: [{role: 'user', content: 'What is the best French cheese?'}],
});

console.log('Chat:', chatResponse.choices[0].message.content);
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/chat/completions" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
    "model": "mistral-large-latest",
    "messages": [{"role": "user", "content": "Who is the most renowned French painter?"}]
  }'
```

----------------------------------------

TITLE: Mistral AI Agents API: List Agents (GET /v1/agents)
DESCRIPTION: Documentation for retrieving a list of existing AI agents. This includes the API endpoint details, authorization requirements, query parameters for pagination, and possible responses.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
GET /v1/agents
Description: Retrieve a list of agent entities sorted by creation time.
Authorizations: ApiKey
Query Parameters:
  page: integer (Page) - Default: 0
  page_size: integer (Page Size) - Default: 20
Responses:
  200: Successful Response
  422: Validation Error
Endpoint: https://api.mistral.ai/v1/agents
```

----------------------------------------

TITLE: Generate Text Embeddings with Mistral AI API
DESCRIPTION: This snippet demonstrates how to use the Mistral AI API to generate text embeddings. It shows how to initialize the client and send a list of input texts to the 'mistral-embed' model. The API returns numerical vectors representing the embeddings, useful for NLP tasks. Requires an activated API key and the Mistral AI client library.
SOURCE: https://docs.mistral.ai/getting-started/quickstart

LANGUAGE: python
CODE:
```
import os
from mistralai import Mistral

api_key = os.environ["MISTRAL_API_KEY"]
model = "mistral-embed"

client = Mistral(api_key=api_key);

embeddings_response = client.embeddings.create(
    model=model,
    inputs=["Embed this sentence.", "As well as this one."]
)

print(embeddings_response);
```

LANGUAGE: typescript
CODE:
```
import { Mistral } from '@mistralai/mistralai';

const apiKey = process.env.MISTRAL_API_KEY;

const client = new Mistral({apiKey: apiKey});

const embeddingsResponse = await client.embeddings.create({
  model: 'mistral-embed',
  inputs: ["Embed this sentence.", "As well as this one."],
});

console.log(embeddingsResponse);
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/embeddings" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
    "model": "mistral-embed",
    "input": ["Embed this sentence.", "As well as this one."]
  }'
```

----------------------------------------

TITLE: Start a New Mistral AI Conversation with Streaming (Client Libraries)
DESCRIPTION: These examples show how to initiate a brand new conversation with the Mistral AI API, enabling real-time streaming of the AI's responses, using the Python and TypeScript client libraries.
SOURCE: https://docs.mistral.ai/agents/agents_basics

LANGUAGE: python
CODE:
```
response = client.beta.conversations.start_stream(
    agent_id=websearch_agent.id,
    inputs="Who is Albert Einstein?"
)
```

LANGUAGE: typescript
CODE:
```
let stream = await client.beta.conversations.startStream({
    agentId: websearchAgent.id,
    inputs: "Who is albert Enstein?"
});
```

----------------------------------------

TITLE: Mistral AI: Batch Job Management API (Get, Create)
DESCRIPTION: This API provides functionalities to manage batch jobs, allowing users to retrieve a list of existing batch jobs with various filtering options and to create new batch jobs by specifying input files, an API endpoint, and a model.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
GET /v1/batch/jobs
  Description: Get a list of batch jobs for your organization and user.
  Authorizations: ApiKey
  Production server: https://api.mistral.ai/v1/batch/jobs
  
  Query Parameters:
    page: integer (Page) - Default: 0
    page_size: integer (Page Size) - Default: 100
    model: string or null (Model)
    metadata: object or null (Metadata)
    created_after: string or null (Created After)
    created_by_me: boolean (Created By Me) - Default: false
    status: Array of strings or null (Status)
  
  Responses:
    200 (OK):
      Content-Type: application/json
      Example:
        {
          "data": [],
          "object": "list",
          "total": 0
        }

POST /v1/batch/jobs
  Description: Create a new batch job, it will be queued for processing.
  Authorizations: ApiKey
  Production server: https://api.mistral.ai/v1/batch/jobs
  
  Request Body (application/json, required):
    input_files (required): Array of strings <uuid> (Input Files)
      Example: ["497f6eca-6276-4993-bfeb-53cbbbba6f08"]
    endpoint (required): string (ApiEndpoint)
      Enum: "/v1/chat/completions", "/v1/embeddings", "/v1/fim/completions", "/v1/moderations", "/v1/chat/moderations"
    model (required): string (Model)
    metadata: object or null (Metadata)
      Example: {"property1": "string", "property2": "string"}
    timeout_hours: integer (Timeout Hours) - Default: 24
  
  Request Sample:
    {
      "input_files": [
        "497f6eca-6276-4993-bfeb-53cbbbba6f08"
      ],
      "endpoint": "/v1/chat/completions",
      "model": "string",
      "metadata": {
        "property1": "string",
        "property2": "string"
      },
      "timeout_hours": 24
    }
  
  Responses:
    200 (OK)
```

----------------------------------------

TITLE: Mistral AI Agents API: Create Agent (POST /v1/agents)
DESCRIPTION: Documentation for creating a new AI agent. This includes the API endpoint details, authorization requirements, request body schema, example payload, and the structure of a successful response. Agents created can be used in conversations or as part of an agent pool.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
POST /v1/agents
Description: Create a new agent giving it instructions, tools, description. The agent is then available to be used as a regular assistant in a conversation or as part of an agent pool from which it can be used.
Authorizations: ApiKey
Request Body Schema (application/json):
  instructions: Instructions (string) or Instructions (null) - Instruction prompt the model will follow during the conversation.
  tools: Array of any (Tools) - List of tools which are available to the model during the conversation.
  completion_args: object (CompletionArgs) - Completion arguments that will be used to generate assistant responses. Can be overridden at each message request.
  model (required): string (Model)
  name (required): string (Name)
  description: Description (string) or Description (null)
  handoffs: Array of Handoffs (strings) or Handoffs (null)
Responses:
  200: Successful Response
  422: Validation Error
Endpoint: https://api.mistral.ai/v1/agents
```

LANGUAGE: JSON
CODE:
```
{
  "instructions": "string",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "string",
        "description": "",
        "strict": false,
        "parameters": {}
      }
    }
  ],
  "completion_args": {
    "stop": "string",
    "presence_penalty": -2,
    "frequency_penalty": -2,
    "temperature": 0.3,
    "top_p": 1,
    "max_tokens": 0,
    "random_seed": 0,
    "prediction": {
      "type": "content",
      "content": ""
    },
    "response_format": {
      "type": "text",
      "json_schema": {
        "name": "string",
        "description": "string",
        "schema": {},
        "strict": false
      }
    },
    "tool_choice": "auto"
  },
  "model": "string",
  "name": "string",
  "description": "string",
  "handoffs": [
    "string"
  ]
}
```

LANGUAGE: JSON
CODE:
```
{
  "instructions": "string",
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "string",
        "description": "",
        "strict": false,
        "parameters": {}
      }
    }
  ],
  "completion_args": {
    "stop": "string",
    "presence_penalty": -2,
    "frequency_penalty": -2,
    "temperature": 0.3,
    "top_p": 1,
    "max_tokens": 0,
    "random_seed": 0,
    "prediction": {
      "type": "content",
      "content": ""
    },
    "response_format": {
      "type": "text",
      "json_schema": {
        "name": "string",
        "description": "string",
        "schema": {},
        "strict": false
      }
    },
    "tool_choice": "auto"
  },
  "model": "string",
  "name": "string",
  "description": "string",
  "handoffs": [
    "string"
  ],
  "object": "agent",
  "id": "string",
  "version": 0,
  "created_at": "2019-08-24T14:15:22Z",
  "updated_at": "2019-08-24T14:15:22Z"
}
```

----------------------------------------

TITLE: Mistral AI Chat Completion API Response Sample
DESCRIPTION: An example JSON response structure for a successful chat completion request, detailing the message content, tool calls, and usage statistics.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: JSON
CODE:
```
{
  "id": "cmpl-e5cc70bb28c444948073e77776eb30ef",
  "object": "chat.completion",
  "model": "mistral-small-latest",
  "usage": {
    "prompt_tokens": 16,
    "completion_tokens": 34,
    "total_tokens": 50
  },
  "created": 1702256327,
  "choices": [
    {
      "index": 0,
      "message": {
        "content": "string",
        "tool_calls": [
          {
            "id": "null",
            "type": "function",
            "function": {
              "name": "string",
              "arguments": {}
            },
            "index": 0
          }
        ],
        "prefix": false,
        "role": "assistant"
      },
      "finish_reason": "stop"
    }
  ]
}
```

----------------------------------------

TITLE: Mistral AI Conversation API Response Example
DESCRIPTION: This section provides a comprehensive example of the JSON structure returned by the Mistral AI Conversations API. It details various components of the response, including the conversation ID, output messages, tool execution results (specifically from the code interpreter with its input code and output), and overall token usage statistics.
SOURCE: https://docs.mistral.ai/agents/connectors/code_interpreter

LANGUAGE: json
CODE:
```
{
  "conversation_id": "conv_06835b9dc0c7749180001958779d13c5",
  "outputs": [
    {
      "content": "Sure, I can help with that. Here's a simple Python function to generate the first 20 Fibonacci numbers.",
      "object": "entry",
      "type": "message.output",
      "created_at": "2025-05-27T13:10:52.208822Z",
      "completed_at": "2025-05-27T13:10:52.470589Z",
      "id": "msg_06835b9dc35772be800073298138bacc",
      "agent_id": "ag_06835b9dbded7f39800034281a63e4f0",
      "model": "mistral-medium-2505",
      "role": "assistant"
    },
    {
      "name": "code_interpreter",
      "object": "entry",
      "type": "tool.execution",
      "created_at": "2025-05-27T13:10:52.561656Z",
      "completed_at": "2025-05-27T13:10:54.431304Z",
      "id": "tool_exec_06835b9dc8fc763880004b7aa94286d8",
      "info": {
        "code": "def fibonacci(n):\n    fib_sequence = [0, 1]\n    for i in range(2, n):\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n    return fib_sequence[:n]\n\nfibonacci_20 = fibonacci(20)\nfibonacci_20",
        "code_output": "[0,\n 1,\n 1,\n 2,\n 3,\n 5,\n 8,\n 13,\n 21,\n 34,\n 55,\n 89,\n 144,\n 233,\n 377,\n 610,\n 987,\n 1597,\n 2584,\n 4181]\n"
      }
    },
    {
      "content": "The first 20 values of the Fibonacci sequence are:\n\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181]",
      "object": "entry",
      "type": "message.output",
      "created_at": "2025-05-27T13:10:54.517935Z",
      "completed_at": "2025-05-27T13:10:55.314698Z",
      "id": "msg_06835b9de84974fa8000f1a97be62f2e",
      "agent_id": "ag_06835b9dbded7f39800034281a63e4f0",
      "model": "mistral-medium-2505",
      "role": "assistant"
    }
  ],
  "usage": {
    "prompt_tokens": 95,
    "completion_tokens": 209,
    "total_tokens": 399,
    "connector_tokens": 95,
    "connectors": {
      "code_interpreter": 1
    }
  },
  "object": "conversation.response"
}
```

----------------------------------------

TITLE: Mistral AI API Data Models and Schemas
DESCRIPTION: Defines the structure of request and response objects for various Mistral AI API endpoints, including chat completions, delta messages, and embedding data. It details properties, types, examples, and relationships between schemas.
SOURCE: https://docs.mistral.ai/redocusaurus/plugin-redoc-0

LANGUAGE: APIDOC
CODE:
```
      type: object
      required:
        - index
        - finish_reason
        - message
      properties:
        index:
          type: integer
          example: 0
        message:
          $ref: '#/components/schemas/AssistantMessage'
        finish_reason:
          type: string
          enum:
            - stop
            - length
            - model_length
            - error
            - tool_calls
          example: stop
    DeltaMessage:
      title: DeltaMessage
      type: object
      properties:
        role:
          anyOf:
            - type: string
            - type: 'null'
        content:
          anyOf:
            - type: string
            - type: 'null'
            - items:
                $ref: '#/components/schemas/ContentChunk'
              type: array
        tool_calls:
          anyOf:
            - type: 'null'
            - type: array
              items:
                $ref: '#/components/schemas/ToolCall'
    ChatCompletionResponseBase:
      allOf:
        - $ref: '#/components/schemas/ResponseBase'
        - type: object
          title: ChatCompletionResponseBase
          properties:
            created:
              type: integer
              example: 1702256327
    ChatCompletionResponse:
      allOf:
        - $ref: '#/components/schemas/ChatCompletionResponseBase'
        - type: object
          title: ChatCompletionResponse
          properties:
            choices:
              type: array
              items:
                $ref: '#/components/schemas/ChatCompletionChoice'
          required:
            - id
            - object
            - data
            - model
            - usage
            - created
            - choices
    FIMCompletionResponse:
      allOf:
        - $ref: '#/components/schemas/ChatCompletionResponse'
        - type: object
          properties:
            model:
              type: string
              example: codestral-latest
    EmbeddingResponseData:
      title: EmbeddingResponseData
      type: object
      properties:
        object:
          type: string
          example: embedding
        embedding:
          type: array
          items:
            type: number
          example:
            - 0.1
            - 0.2
            - 0.3
        index:
          type: integer
          example: 0
      examples:
        - object: embedding
          embedding:
            - 0.1
            - 0.2
            - 0.3
          index: 0
        - object: embedding
          embedding:
            - 0.4
            - 0.5
            - 0.6
          index: 1
    EmbeddingResponse:
      allOf:
        - $ref: '#/components/schemas/ResponseBase'
        - type: object
          properties:
            data:
              type: array
              items:
                - $ref: '#/components/schemas/EmbeddingResponseData'
          required:
            - id
            - object
            - data
            - model
            - usage
```

----------------------------------------

TITLE: Mistral AI Conversation API Response Structure Example
DESCRIPTION: Illustrates the detailed JSON structure of a successful response from the Mistral AI conversation API. This example shows the `conversation_id`, an array of `outputs` (including `tool.execution` and `message.output` types), and `usage` statistics. The `message.output` content provides a comprehensive explanation of the Pixtral 12B vision encoder.
SOURCE: https://docs.mistral.ai/agents/connectors/document_library

LANGUAGE: json
CODE:
```
{
  "conversation_id": "conv_06835bb1996079898000435d8a0b1afd",
  "outputs": [
    {
      "type": "tool.execution",
      "name": "document_library",
      "object": "entry",
      "created_at": "2025-05-27T13:16:09.974925Z",
      "completed_at": "2025-05-27T13:16:10.855373Z",
      "id": "tool_exec_06835bb19f99716580001de8ab64d953"
    },
    {
      "type": "message.output",
      "content": [
        {
          "type": "text",
          "text": "The vision encoder for Pixtral 12B, known as PixtralViT, is designed to process images at their natural resolution and aspect ratio. Here are the key details about how it works:\n\n1. **Architecture**: PixtralViT is a vision transformer with 400 million parameters. It is trained from scratch to support variable image sizes and aspect ratios, which is a significant departure from standard architectures that often require fixed image sizes.\n\n2. **Key Modifications**:\n   - **Break Tokens**: To help the model distinguish between images with the same number of patches but different aspect ratios, special tokens like [IMAGE BREAK] are inserted between image rows, and an [IMAGE END] token is added at the end of an image sequence.\n   - **Gating in FFN**: Instead of using a standard feedforward layer in the attention block, PixtralViT employs gating in the hidden layer, which enhances its performance.\n   - **Sequence Packing**: Images are flattened along the sequence dimension and concatenated to process multiple images efficiently within a single batch. A block-diagonal mask ensures no attention leakage between patches from different images.\n   - **RoPE-2D**: Traditional position embeddings are replaced with relative, rotary position encodings (RoPE-2D) in the self-attention layers. This allows the model to handle variable image sizes more effectively without the need for interpolation, which can degrade performance.\n\n3. **Integration with Multimodal Decoder**: The vision encoder is linked to the multimodal decoder via a two-layer fully connected network. This network transforms the output of the vision encoder into the input embedding size required by the decoder. The image tokens are treated similarly to text tokens by the multimodal decoder, which uses RoPE-1D positional encodings for all tokens.\n\n4. **Performance**: The Pixtral vision encoder significantly outperforms other models in tasks requiring fine-grained document understanding while maintaining parity for natural images. It is particularly effective in settings that require detailed visual comprehension, such as chart and document understanding.\n\nThese architectural choices and modifications enable Pixtral 12B to flexibly process images at various resolutions and aspect ratios, making it highly versatile for complex multimodal applications."
        }
      ],
      "object": "entry",
      "created_at": "2025-05-27T13:16:11.239496Z",
      "completed_at": "2025-05-27T13:16:17.211241Z",
      "id": "msg_06835bb1b3d47ca580001b213d836798",
      "agent_id": "ag_06835bb196f9720680004fb1873efbae",
      "model": "mistral-medium-2505",
      "role": "assistant"
    }
  ],
  "usage": {
    "prompt_tokens": 196,
    "completion_tokens": 485,
    "total_tokens": 3846,
    "
```

----------------------------------------

TITLE: Mistral AI Agents Completion API Reference
DESCRIPTION: Documents the `POST /v1/agents/completions` endpoint for generating AI completions via an agent. It details the request body parameters, including message prompts, token limits, streaming options, and agent-specific configurations, along with response types and an example request payload.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Endpoint: POST /v1/agents/completions
Base URL: https://api.mistral.ai/v1/agents/completions
Authorizations: ApiKey

Request Body Schema (application/json - required):
  max_tokens: integer or null (Max Tokens)
    Description: The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
  stream: boolean (Stream)
    Default: false
    Description: Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.
  stop: string or Array of string (Stop)
    Description: Stop generation if this token is detected. Or if one of these tokens is detected when providing an array.
  random_seed: integer or null (Random Seed)
    Description: The seed to use for random sampling. If set, different calls will generate deterministic results.
  messages (required): Array of any (Messages)
    Description: The prompt(s) to generate completions for, encoded as a list of dict with role and content.
  response_format: object (ResponseFormat)
  tools: Array of objects or null (Tools)
  tool_choice: object or string (Tool Choice)
    Default: "auto"
  presence_penalty: number [-2 .. 2] (Presence Penalty)
    Default: 0
    Description: Determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.
  frequency_penalty: number [-2 .. 2] (Frequency Penalty)
    Default: 0
    Description: Penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition.
  n: integer or null (N)
    Description: Number of completions to return for each request, input tokens are only billed once.
  prediction: object (Prediction)
    Default: {"type":"content","content":""}
    Description: Enable users to specify expected results, optimizing response times by leveraging known or predictable content. This approach is especially effective for updating text documents or code files with minimal changes, reducing latency while maintaining high-quality results.
  parallel_tool_calls: boolean (Parallel Tool Calls)
    Default: true
  prompt_mode: string or null (MistralPromptMode)
    Description: Allows toggling between the reasoning mode and no system prompt. When set to `reasoning` the system prompt for reasoning models will be used.
  agent_id (required): string
    Description: The ID of the agent to use for this completion.

Responses:
  200: Successful Response
  422: Validation Error

Request Sample Payload (application/json):
{
  "max_tokens": 0,
  "stream": false,
  "stop": "string",
  "random_seed": 0,
  "messages": [
    {
      "role": "user",
      "content": "Who is the best French painter? Answer in one short sentence."
    }
  ],
  "response_format": {
    "type": "text",
    "json_schema": {
      "name": "string",
      "description": "string",
      "schema": {},
      "strict": false
    }
  },
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "string",
        "description": "",
        "strict": false,
        "parameters": {}
      }
    }
  ],
  "tool_choice": "auto",
  "presence_penalty": 0,
  "frequency_penalty": 0,
  "n": 1,
  "prediction": {
    "type": "content",
    "content": ""
  },
  "parallel_tool_calls": true,
  "prompt_mode": "reasoning",
  "agent_id": "string"
}
```

----------------------------------------

TITLE: Mistral Embeddings API Response Structure Example
DESCRIPTION: Illustrates the typical structure of the `EmbeddingResponse` object returned by the Mistral AI Embeddings API. This JSON-like output includes the generated embeddings data, the model used, and token usage statistics, providing insight into the API's return format.
SOURCE: https://docs.mistral.ai/capabilities/embeddings/text_embeddings

LANGUAGE: json
CODE:
```
EmbeddingResponse(
    id='eb4c2c739780415bb3af4e47580318cc', object='list', data=[
        Data(object='embedding', embedding=[-0.0165863037109375,...], index=0),
        Data(object='embedding', embedding=[-0.0234222412109375,...], index=1)],
    model='mistral-embed', usage=EmbeddingResponseUsage(prompt_tokens=15, total_tokens=15)
)
```

----------------------------------------

TITLE: Download File Content via cURL (Mistral AI API)
DESCRIPTION: Example cURL command to directly download file content from the Mistral AI API using a specific file ID. This command requires an API key for authentication and sets appropriate `Accept` headers for binary data.
SOURCE: https://docs.mistral.ai/agents/connectors/image_generation

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/files/<file_id>/content" \
     --header 'Accept: application/octet-stream' \
     --header 'Accept-Encoding: gzip, deflate, zstd' \
     --header "Authorization: Bearer $MISTRAL_API_KEY"
```

----------------------------------------

TITLE: Mistral AI Files API: List Files
DESCRIPTION: Documents the API for retrieving a list of files belonging to the user's organization, with options for pagination and filtering by sample type, source, search term, or purpose.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Method: GET /v1/files
Production Server: https://api.mistral.ai/v1/files
Authorizations: ApiKey

Query Parameters:
  page: integer (Page) - Default: 0
  page_size: integer (Page Size) - Default: 100
  sample_type: Array of Sample Type (strings) or Sample Type (null)
  source: Array of Source (strings) or Source (null)
  search: Search (string) or Search (null)
  purpose: FilePurpose (string) or null

Response (200 OK):
  Description: OK
  Content Type: application/json
  Body:
    data: array
      id: string
      object: string
      bytes: number
      created_at: number
      filename: string
      purpose: string
      sample_type: string
      num_lines: number
      source: string
    object: string
    total: number
```

----------------------------------------

TITLE: Mistral AI Fine-Tuning API: Get Jobs
DESCRIPTION: Retrieves a list of fine-tuning jobs associated with your organization and user. This endpoint supports various filtering options based on pagination, model, creation date, status, and Weights & Biases project details.
SOURCE: https://docs.mistral.ai/api

LANGUAGE: APIDOC
CODE:
```
Endpoint: get/v1/fine_tuning/jobs
  Description: Get a list of fine-tuning jobs for your organization and user.
  Authorizations: ApiKey
  Query Parameters:
    - page: integer (optional, default: 0) - The page number of the results to be returned.
    - page_size: integer (optional, default: 100) - The number of items to return per page.
    - model: string or null (optional) - The model name used for fine-tuning to filter on.
    - created_after: string or null (optional) - The date/time to filter on.
    - created_before: string or null (optional) - The date/time to filter on.
    - created_by_me: boolean (optional, default: false) - When set, only return results for jobs created by the API caller.
    - status: string or null (optional) - The current job state to filter on.
    - wandb_project: string or null (optional) - The Weights and Biases project to filter on.
    - wandb_name: string or null (optional) - The Weight and Biases run name to filter on.
    - suffix: string or null (optional) - The model suffix to filter on.
  Responses:
    - 200 OK
  Response Sample (application/json):
    {
      "data": [ ],
      "object": "list",
      "total": 0
    }
```

----------------------------------------

TITLE: Example JSON Response for Mistral AI Conversation
DESCRIPTION: Illustrates the typical JSON structure returned by the Mistral AI API after successfully starting and completing a conversation. It includes details about the conversation ID, output messages, usage statistics, and object type.
SOURCE: https://docs.mistral.ai/agents/agents_basics

LANGUAGE: json
CODE:
```
{
  "conversation_id": "conv_0684fe18cbc57ba6800065acdd2b6c85",
  "outputs": [
    {
      "content": "Albert Einstein was a German-born theoretical physicist who is widely regarded as one of the most influential scientists of the 20th century. He is best known for developing the theory of relativity, which revolutionized our understanding of space, time, and energy. Einstein's work also made significant contributions to the development of quantum mechanics and statistical mechanics.\n\nSome of his most notable achievements include:\n\n1. **Special Theory of Relativity (1905)**: This theory introduced the idea that the laws of physics are the same for all non-accelerating observers and that the speed of light in a vacuum is constant, regardless of the observer's motion.\n\n2. **General Theory of Relativity (1915)**: This theory extended the principles of special relativity to include gravity, describing it as a property of the geometry of space and time.\n\n3. **Mass-Energy Equivalence (E=mc²)**: This famous equation from his special theory of relativity shows that mass and energy are interchangeable.\n\n4. **Photoelectric Effect**: Einstein's explanation of the photoelectric effect, which suggested that light could be described as discrete packets of energy (quanta or photons), was a pivotal step in the development of quantum theory.\n\nEinstein was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. He was also known for his humanitarian efforts and his advocacy for civil rights and peace. Einstein emigrated to the United States in the 1930s to escape the rise of the Nazi regime in Germany and became a professor at the Institute for Advanced Study in Princeton, New Jersey, where he spent the remainder of his career.\n\nEinstein's work continues to influence modern physics and our understanding of the universe. He passed away on April 18, 1955.",
      "object": "entry",
      "type": "message.output",
      "created_at": "2025-06-16T09:19:09.031905Z",
      "completed_at": "2025-06-16T09:19:15.138424Z",
      "id": "msg_0684fe18d08278058000efa70b28fa5a",
      "agent_id": "ag_0684fe0e0b98773e8000323fc71a3986",
      "model": "mistral-medium-2505",
      "role": "assistant"
    }
  ],
  "usage": {
    "prompt_tokens": 8,
    "completion_tokens": 370,
    "total_tokens": 378,
    "connector_tokens": null,
    "connectors": null
  },
  "object": "conversation.response"
}
```

----------------------------------------

TITLE: Create a Document Library Agent via API
DESCRIPTION: This snippet demonstrates how to programmatically create an AI agent that has access to a document library. The agent is configured with a specific model, name, description, instructions, and a tool of type 'document_library' linked by `library_ids`. This allows the agent to leverage knowledge from uploaded documents. The `completion_args` specify parameters like temperature and top_p for response generation. An example of the successful API response is also provided.
SOURCE: https://docs.mistral.ai/agents/connectors/document_library

LANGUAGE: python
CODE:
```
library_agent = client.beta.agents.create(
    model="mistral-medium-2505",
    name="Document Library Agent",
    description="Agent used to access documents from the document library.",
    instructions="Use the  library tool to access external documents.",
    tools=[{"type": "document_library", "library_ids": ["<library_id>"]}],
    completion_args={
        "temperature": 0.3,
        "top_p": 0.95,
    }
)
```

LANGUAGE: typescript
CODE:
```
let libraryAgent = await client.beta.agents.create({
    model:"mistral-medium-2505",
    name:"Document Library Agent",
    description:"Agent used to access documents from the document library.",
    instructions:"Use the  library tool to access external documents.",
    tools:[
        {
            type: "document_library",
            libraryIds: ["<library_id>"]
        }
    ],
    completionArgs:{
        temperature: 0.3,
        topP: 0.95,
    }
});
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/agents" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
     "model": "mistral-medium-2505",
     "name": "Library Agent",
     "description": "Agent able to search information in your library...",
     "instructions": "You have the ability to perform searches with `document_library` to find relevant information.",
     "tools": [
       {
         "type": "document_library",
         "library_ids" : ["<library_id>"]
       }
     ],
     "completion_args": {
       "temperature": 0.3,
       "top_p": 0.95
     }
  }'
```

LANGUAGE: json
CODE:
```
{
  "model": "mistral-medium-2505",
  "name": "Document Library Agent",
  "description": "Agent used to access documents from the document library.",
  "id": "ag_06835bb196f9720680004fb1873efbae",
  "version": 0,
  "created_at": "2025-05-27T13:16:09.438785Z",
  "updated_at": "2025-05-27T13:16:09.438787Z",
  "instructions": "Use the library tool to access external documents.",
  "tools": [
    {
      "library_ids": [
        "06835a9c-262c-7e83-8000-594d29fe2948"
      ],
      "type": "document_library"
    }
  ],
  "completion_args": {
    "stop": null,
    "presence_penalty": null,
    "frequency_penalty": null,
    "temperature": 0.3,
    "top_p": 0.95,
    "max_tokens": null,
    "random_seed": null,
    "prediction": null,
    "response_format": null,
    "tool_choice": "auto"
  },
  "handoffs": null,
  "object": "agent"
}
```

----------------------------------------

TITLE: Generate Text Embeddings with Mistral Embed API
DESCRIPTION: Demonstrates how to generate text embeddings using the Mistral AI Embed API. It shows examples in Python, TypeScript, and cURL for sending input texts to the `mistral-embed` model and receiving numerical vector embeddings. An `MISTRAL_API_KEY` environment variable is required for authentication.
SOURCE: https://docs.mistral.ai/capabilities/embeddings/text_embeddings

LANGUAGE: python
CODE:
```
import os
from mistralai import Mistral

api_key = os.environ["MISTRAL_API_KEY"]
model = "mistral-embed"

client = Mistral(api_key=api_key)

embeddings_batch_response = client.embeddings.create(
    model=model,
    inputs=["Embed this sentence.", "As well as this one."],
)
```

LANGUAGE: typescript
CODE:
```
import { Mistral } from '@mistralai/mistralai';

const apiKey = process.env.MISTRAL_API_KEY;

const client = new Mistral({ apiKey: apiKey });

async function getEmbeddings() {

    const embeddingsBatchResponse = await client.embeddings.create({
        model: "mistral-embed",
        inputs: ["Embed this sentence.", "As well as this one."],
    });

    console.log('Embeddings:', embeddingsBatchResponse.data);
}

// Call the async function
getEmbeddings().catch(console.error);
```

LANGUAGE: curl
CODE:
```
curl -X POST "https://api.mistral.ai/v1/embeddings" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer ${API_KEY}" \
     -d '{"model": "mistral-embed", "input": ["Embed this sentence.", "As well as this one."]}' \
     -o embedding.json
```

----------------------------------------

TITLE: Example Output for Mistral AI Agent Creation
DESCRIPTION: Provides an example of the JSON response received after successfully creating a Mistral AI agent through the API. It includes details like the agent's model, name, description, and a unique ID.
SOURCE: https://docs.mistral.ai/agents/function_calling

LANGUAGE: json
CODE:
```
{
  "model": "mistral-medium-2505",
  "name": "ecb-interest-rate-agent",
  "description": "Can find the current interest rate of the European central bank",
  "id": "ag_06835a34f2c476518000c372a505c2c4",
  "version": 0
}
```

----------------------------------------

TITLE: Mistral AI Fine-Tuning Jobs Listing and Creation API
DESCRIPTION: Provides endpoints for listing existing fine-tuning jobs and creating new ones. This API allows users to manage the lifecycle of their fine-tuning processes, from initiation to monitoring.
SOURCE: https://docs.mistral.ai/redocusaurus/plugin-redoc-0

LANGUAGE: APIDOC
CODE:
```
GET /v1/fine_tuning/jobs
  Summary: List Fine Tuning Jobs
  Description: Retrieves a list of all fine-tuning jobs, along with some of their input parameters.
  Responses:
    '200 OK':
      Description: Successfully retrieved the list of jobs.
      Content:
        application/json:
          Schema: anyOf
            - discriminator:
                mapping:
                  classifier: '#/components/schemas/ClassifierJobOut'
                  completion: '#/components/schemas/CompletionJobOut'
                propertyName: job_type
              oneOf:
                - $ref: '#/components/schemas/CompletionJobOut'
                - $ref: '#/components/schemas/ClassifierJobOut'
            - $ref: '#/components/schemas/LegacyJobMetadataOut'
```

LANGUAGE: APIDOC
CODE:
```
POST /v1/fine_tuning/jobs
  Summary: Create Fine Tuning Job
  Description: Creates a new fine-tuning job, which will be queued for processing.
  Request Body:
    Content:
      application/json:
        Schema: $ref: '#/components/schemas/JobIn'
    Required: true
  Responses:
    '200 OK':
      Description: Successfully created the fine-tuning job.
      Content:
        application/json:
          Schema: anyOf
            - discriminator:
                mapping:
                  classifier: '#/components/schemas/ClassifierJobOut'
                  completion: '#/components/schemas/CompletionJobOut'
                propertyName: job_type
              oneOf:
                - $ref: '#/components/schemas/CompletionJobOut'
                - $ref: '#/components/schemas/ClassifierJobOut'
            - $ref: '#/components/schemas/LegacyJobMetadataOut'
```

----------------------------------------

TITLE: Continue Conversation with Mistral AI
DESCRIPTION: Demonstrates how to append new inputs to an existing conversation using the Mistral AI API, maintaining conversation history. Examples are provided for Python, TypeScript, and cURL, showing how to pass conversation ID, inputs, and optional completion arguments.
SOURCE: https://docs.mistral.ai/agents/agents_basics

LANGUAGE: python
CODE:
```
response = client.beta.conversations.append(
    conversation_id=response.conversation_id,
    inputs="Translate to French."
)
```

LANGUAGE: typescript
CODE:
```
conversation = await client.beta.conversations.append({
    conversationId: conversation.conversationId,
    conversationAppendRequest:
    {
        inputs:[{role: "user", content:"Who is Albert Einstein?"}],
        completionArgs: {
            temperature: 0.3,
            topP: 0.95,
        }
    },
    //store:false
});
```

LANGUAGE: curl
CODE:
```
curl --location "https://api.mistral.ai/v1/conversations/<conv_id>" \
     --header 'Content-Type: application/json' \
     --header 'Accept: application/json' \
     --header "Authorization: Bearer $MISTRAL_API_KEY" \
     --data '{
     "inputs": "Translate to French.",
     "stream": false,
     "store": true,
     "handoff_execution": "server"
  }'
```